{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from PDFChatBot import PDFChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4()).replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'OLLAMA_API_BASE_URL' not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = config('OPENAI_API_KEY')\n",
    "OLLAMA_API_BASE_URL = os.environ['OLLAMA_API_BASE_URL'] if 'OLLAMA_API_BASE_URL' in os.environ else config('OLLAMA_API_BASE_URL')   \n",
    "LLM = os.environ['LLM'] if 'LLM' in os.environ else config('LLM')   \n",
    "EMBEDDING_MODEL = os.environ['EMBEDDING_MODEL'] if 'EMBEDDING_MODEL' in os.environ else config('EMBEDDING_MODEL')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stolli/miniforge3/envs/pdf-chat-bot/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/stolli/miniforge3/envs/pdf-chat-bot/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f'Using embedding model: {EMBEDDING_MODEL}')\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LLM: llama3.1:8b\n"
     ]
    }
   ],
   "source": [
    "print(f'Using LLM: {LLM}')\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_API_BASE_URL, \n",
    "    model=LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PDF Chatbot ...\n",
      "--- Loading and vectorizing PDF file ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing history aware LLM ---\n"
     ]
    }
   ],
   "source": [
    "chat_bot = PDFChatBot('/Users/stolli/IT/Designing Data-Intensive Applications.pdf', embedding_model, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What is partitioning?', 'chat_history': []}\n",
      "{'context': [Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'), Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'), Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'), Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199')]}\n",
      "{'answer': 'Partition'}\n",
      "{'answer': 'ing'}\n",
      "{'answer': ' is'}\n",
      "{'answer': ' dividing'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' into'}\n",
      "{'answer': ' smaller'}\n",
      "{'answer': ','}\n",
      "{'answer': ' independent'}\n",
      "{'answer': ' pieces'}\n",
      "{'answer': ' ('}\n",
      "{'answer': 'called'}\n",
      "{'answer': ' partitions'}\n",
      "{'answer': ' or'}\n",
      "{'answer': ' shards'}\n",
      "{'answer': ')'}\n",
      "{'answer': ' so'}\n",
      "{'answer': ' that'}\n",
      "{'answer': ' each'}\n",
      "{'answer': ' piece'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' belongs'}\n",
      "{'answer': ' to'}\n",
      "{'answer': ' exactly'}\n",
      "{'answer': ' one'}\n",
      "{'answer': ' partition'}\n",
      "{'answer': '.'}\n",
      "{'answer': ' Each'}\n",
      "{'answer': ' partition'}\n",
      "{'answer': ' acts'}\n",
      "{'answer': ' as'}\n",
      "{'answer': ' a'}\n",
      "{'answer': ' small'}\n",
      "{'answer': ' database'}\n",
      "{'answer': ','}\n",
      "{'answer': ' and'}\n",
      "{'answer': ' different'}\n",
      "{'answer': ' partitions'}\n",
      "{'answer': ' can'}\n",
      "{'answer': ' be'}\n",
      "{'answer': ' placed'}\n",
      "{'answer': ' on'}\n",
      "{'answer': ' different'}\n",
      "{'answer': ' nodes'}\n",
      "{'answer': ' in'}\n",
      "{'answer': ' a'}\n",
      "{'answer': ' shared'}\n",
      "{'answer': '-no'}\n",
      "{'answer': 'thing'}\n",
      "{'answer': ' cluster'}\n",
      "{'answer': ' for'}\n",
      "{'answer': ' improved'}\n",
      "{'answer': ' scalability'}\n",
      "{'answer': '.'}\n",
      "{'answer': ''}\n"
     ]
    }
   ],
   "source": [
    "stream_response = []\n",
    "async for chunk in chat_bot.stream_response('What is partitioning?', session_id):\n",
    "    stream_response.append(chunk)\n",
    "    print(chunk, end=\"\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating response ---\n"
     ]
    }
   ],
   "source": [
    "response = chat_bot.get_response('What is the book about? Please summarize it in around 20 sentences. Include a list of the most important topics', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text appears to be an excerpt from a discussion or tutorial about partitioning data, likely in a distributed database system.\n",
      "\n",
      "Here's a summary:\n",
      "\n",
      "Partitioning is a technique used to spread data and query load evenly across multiple machines (nodes) in a cluster. This approach helps avoid hot spots, which are nodes with disproportionately high loads. The goal of partitioning is to choose an appropriate scheme for the data and rebalance partitions when nodes are added or removed from the cluster.\n",
      "\n",
      "There are two main approaches to partitioning:\n",
      "\n",
      "1. **Key Range Partitioning**: Keys are sorted, and a partition owns all keys from a minimum up to a maximum value. This approach allows efficient range queries but risks hot spots if the application often accesses keys close together.\n",
      "2. **Hash Partitioning**: A hash function is applied to each key, and a partition owns a range of hashes. This method destroys key ordering, making range queries less efficient.\n",
      "\n",
      "Partitions in Key Range Partitioning are typically rebalanced dynamically by splitting the range into two subranges when a partition gets too big.\n",
      "\n",
      "The text discusses these two main approaches to partitioning but does not provide further details on other topics.\n",
      "\n",
      "Most important topics:\n",
      "\n",
      "1. **Key Range Partitioning**\n",
      "2. **Hash Partitioning**\n",
      "3. **Partition Rebalancing**\n",
      "4. **Hot Spots and Load Distribution**\n",
      "5. **Choosing a Partitioning Scheme**\n",
      "\n",
      "Please note that the provided text is quite concise, so this summary might not cover all aspects of partitioning in distributed databases.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The goal of partitioning is to spread the data and query load evenly across multiple\\nmachines, avoiding hot spots (nodes with disproportionately high load). This\\nrequires choosing a partitioning scheme that is appropriate to your data, and reba‐\\nlancing the partitions when nodes are added to or removed from the cluster.\\nWe discussed two main approaches to partitioning:\\n•Key range partitioning , where keys are sorted, and a partition owns all the keys\\nfrom some minimum up to some maximum. Sorting has the advantage that effi‐\\ncient range queries are possible, but there is a risk of hot spots if the application\\noften accesses keys that are close together in the sorted order.\\nIn this approach, partitions are typically rebalanced dynamically by splitting the\\nrange into two subranges when a partition gets too big.\\n•Hash partitioning , where a hash function is applied to each key, and a partition\\nowns a range of hashes. This method destroys the ordering of keys, making range'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context'][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 238\n",
      "Content: The goal of partitioning is to spread the data and query load evenly across multiple\n",
      "machines, avoiding hot spots (nodes with disproportionately high load). This\n",
      "requires choosing a partitioning scheme that is appropriate to your data, and reba‐\n",
      "lancing the partitions when nodes are added to or removed from the cluster.\n",
      "We discussed two main approaches to partitioning:\n",
      "•Key range partitioning , where keys are sorted, and a partition owns all the keys\n",
      "from some minimum up to some maximum. Sorting has the advantage that effi‐\n",
      "cient range queries are possible, but there is a risk of hot spots if the application\n",
      "often accesses keys that are close together in the sorted order.\n",
      "In this approach, partitions are typically rebalanced dynamically by splitting the\n",
      "range into two subranges when a partition gets too big.\n",
      "•Hash partitioning , where a hash function is applied to each key, and a partition\n",
      "owns a range of hashes. This method destroys the ordering of keys, making range\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 238\n",
      "Content: The goal of partitioning is to spread the data and query load evenly across multiple\n",
      "machines, avoiding hot spots (nodes with disproportionately high load). This\n",
      "requires choosing a partitioning scheme that is appropriate to your data, and reba‐\n",
      "lancing the partitions when nodes are added to or removed from the cluster.\n",
      "We discussed two main approaches to partitioning:\n",
      "•Key range partitioning , where keys are sorted, and a partition owns all the keys\n",
      "from some minimum up to some maximum. Sorting has the advantage that effi‐\n",
      "cient range queries are possible, but there is a risk of hot spots if the application\n",
      "often accesses keys that are close together in the sorted order.\n",
      "In this approach, partitions are typically rebalanced dynamically by splitting the\n",
      "range into two subranges when a partition gets too big.\n",
      "•Hash partitioning , where a hash function is applied to each key, and a partition\n",
      "owns a range of hashes. This method destroys the ordering of keys, making range\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 238\n",
      "Content: The goal of partitioning is to spread the data and query load evenly across multiple\n",
      "machines, avoiding hot spots (nodes with disproportionately high load). This\n",
      "requires choosing a partitioning scheme that is appropriate to your data, and reba‐\n",
      "lancing the partitions when nodes are added to or removed from the cluster.\n",
      "We discussed two main approaches to partitioning:\n",
      "•Key range partitioning , where keys are sorted, and a partition owns all the keys\n",
      "from some minimum up to some maximum. Sorting has the advantage that effi‐\n",
      "cient range queries are possible, but there is a risk of hot spots if the application\n",
      "often accesses keys that are close together in the sorted order.\n",
      "In this approach, partitions are typically rebalanced dynamically by splitting the\n",
      "range into two subranges when a partition gets too big.\n",
      "•Hash partitioning , where a hash function is applied to each key, and a partition\n",
      "owns a range of hashes. This method destroys the ordering of keys, making range\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 238\n",
      "Content: The goal of partitioning is to spread the data and query load evenly across multiple\n",
      "machines, avoiding hot spots (nodes with disproportionately high load). This\n",
      "requires choosing a partitioning scheme that is appropriate to your data, and reba‐\n",
      "lancing the partitions when nodes are added to or removed from the cluster.\n",
      "We discussed two main approaches to partitioning:\n",
      "•Key range partitioning , where keys are sorted, and a partition owns all the keys\n",
      "from some minimum up to some maximum. Sorting has the advantage that effi‐\n",
      "cient range queries are possible, but there is a risk of hot spots if the application\n",
      "often accesses keys that are close together in the sorted order.\n",
      "In this approach, partitions are typically rebalanced dynamically by splitting the\n",
      "range into two subranges when a partition gets too big.\n",
      "•Hash partitioning , where a hash function is applied to each key, and a partition\n",
      "owns a range of hashes. This method destroys the ordering of keys, making range\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in response['context']:\n",
    "    print(f'Source: {document.metadata[\"source\"]}')\n",
    "    print(f'Page: {document.metadata[\"page\"]}')\n",
    "    print(f'Content: {document.page_content}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_bot.get_response('What is partitioning?', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_bot.get_response('Can you repeat the answer as structured list?', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What is partitioning?', 'chat_history': [HumanMessage(content='What is partitioning?', additional_kwargs={}, response_metadata={}), AIMessage(content='Partitioning is dividing data into smaller, independent pieces (called partitions or shards) so that each piece of data belongs to exactly one partition. Each partition acts as a small database, and different partitions can be placed on different nodes in a shared-nothing cluster for improved scalability.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the book about? Please summarize it in around 20 sentences. Include a list of the most important topics', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The text appears to be an excerpt from a discussion or tutorial about partitioning data, likely in a distributed database system.\\n\\nHere's a summary:\\n\\nPartitioning is a technique used to spread data and query load evenly across multiple machines (nodes) in a cluster. This approach helps avoid hot spots, which are nodes with disproportionately high loads. The goal of partitioning is to choose an appropriate scheme for the data and rebalance partitions when nodes are added or removed from the cluster.\\n\\nThere are two main approaches to partitioning:\\n\\n1. **Key Range Partitioning**: Keys are sorted, and a partition owns all keys from a minimum up to a maximum value. This approach allows efficient range queries but risks hot spots if the application often accesses keys close together.\\n2. **Hash Partitioning**: A hash function is applied to each key, and a partition owns a range of hashes. This method destroys key ordering, making range queries less efficient.\\n\\nPartitions in Key Range Partitioning are typically rebalanced dynamically by splitting the range into two subranges when a partition gets too big.\\n\\nThe text discusses these two main approaches to partitioning but does not provide further details on other topics.\\n\\nMost important topics:\\n\\n1. **Key Range Partitioning**\\n2. **Hash Partitioning**\\n3. **Partition Rebalancing**\\n4. **Hot Spots and Load Distribution**\\n5. **Choosing a Partitioning Scheme**\\n\\nPlease note that the provided text is quite concise, so this summary might not cover all aspects of partitioning in distributed databases.\", additional_kwargs={}, response_metadata={})]}\n",
      "{'context': [Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'), Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'), Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'), Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199')]}\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in chat_bot._rag_chain_with_history.astream(\n",
    "    {\"input\": 'What is partitioning?'},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": session_id}\n",
    "    }\n",
    "):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'What is partitioning?',\n",
       "  'chat_history': [HumanMessage(content='What is the book about? Please summarize it in around 20 sentences. Include a list of the most important topics', additional_kwargs={}, response_metadata={}),\n",
       "   AIMessage(content='Based on the provided context, here\\'s a summary of the book \"Designing Data-Intensive Applications\" by Martin Kleppmann:\\n\\n**Summary**\\n\\nThe book is about designing and building data-intensive applications that can scale to handle large amounts of data. The author, Martin Kleppmann, draws from his experience as a researcher in distributed systems at the University of Cambridge and a software engineer at companies like LinkedIn.\\n\\nKleppmann shares lessons learned from working on large-scale data infrastructure projects, highlighting common mistakes and pitfalls to avoid. He emphasizes the importance of understanding fundamental technical concepts, making them accessible to everyone, and promoting deeper understanding to develop better software.\\n\\nThe book covers various topics related to designing data-intensive applications, including data storage, processing, and streaming. Kleppmann discusses different approaches to handling data, such as relational databases, NoSQL databases, and distributed systems.\\n\\n**Most Important Topics**\\n\\nHere\\'s a list of the most important topics covered in the book:\\n\\n1. **Database Inside-Out Concept**: The author explores the idea of turning the database inside-out, where the application takes on more responsibilities, and the database becomes a mere data store.\\n2. **Distributed Systems**: Kleppmann discusses the principles and challenges of designing distributed systems that can handle large amounts of data.\\n3. **Data Storage**: He covers various data storage options, including relational databases, NoSQL databases, and distributed storage solutions like Apache Samza.\\n4. **Data Processing**: The book explores different approaches to processing data, such as batch processing, streaming, and event-driven architectures.\\n5. **Data Streaming**: Kleppmann discusses the use of streaming technologies, like Apache Kafka, for handling high-volume and high-velocity data streams.\\n6. **Scalability**: He emphasizes the importance of designing systems that can scale horizontally to handle increasing data volumes.\\n7. **Fault Tolerance**: The book covers strategies for building fault-tolerant systems that can recover from failures and maintain availability.\\n8. **Data Consistency**: Kleppmann discusses the trade-offs between consistency, availability, and partition tolerance (CAP theorem) in designing distributed systems.\\n\\nThe book aims to provide a comprehensive guide for software engineers, architects, and developers who want to build scalable, fault-tolerant, and data-intensive applications.', additional_kwargs={}, response_metadata={}),\n",
       "   HumanMessage(content='What is partitioning?', additional_kwargs={}, response_metadata={}),\n",
       "   AIMessage(content='According to the provided context, \"partitioning\" refers to dividing data into smaller chunks or partitions, where each piece of data (record, row, or document) belongs to exactly one partition. This process is also known by different names in various databases and systems, such as:\\n\\n* Sharding in MongoDB, Elasticsearch, and SolrCloud\\n* Region in HBase\\n* Tablet in Bigtable\\n* Vnode in Cassandra and Riak\\n* vBucket in Couchbase\\n\\nThe main reason for partitioning data is to achieve scalability. By placing different partitions on different nodes in a shared-nothing cluster, the system can handle increasing amounts of data without significant performance degradation.\\n\\nIn essence, each partition acts as a small database of its own, although the overall database may support operations that touch multiple partitions at the same time.', additional_kwargs={}, response_metadata={}),\n",
       "   HumanMessage(content='What is partitioning?', additional_kwargs={}, response_metadata={}),\n",
       "   AIMessage(content='According to the text, partitioning is dividing data into smaller chunks or partitions, where each piece of data (record, row, or document) belongs to exactly one partition. This process allows for scalability by placing different partitions on different nodes in a shared-nothing cluster.', additional_kwargs={}, response_metadata={}),\n",
       "   HumanMessage(content='What is partitioning?', additional_kwargs={}, response_metadata={}),\n",
       "   AIMessage(content='Partitioning refers to dividing large datasets into smaller, more manageable chunks called partitions, so that data can be stored, processed, and retrieved efficiently.', additional_kwargs={}, response_metadata={})]},\n",
       " {'context': [Document(metadata={'page': 237, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='overview of techniques used in parallel databases, please see the references [ 1, 33]. \\nSummary\\nIn this chapter we explored different ways of partitioning a large dataset into smaller\\nsubsets. Partitioning is necessary when you have so much data that storing and pro‐\\ncessing it on a single machine is no longer feasible.\\n216 | Chapter 6: Partitioning'),\n",
       "   Document(metadata={'page': 237, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='overview of techniques used in parallel databases, please see the references [ 1, 33]. \\nSummary\\nIn this chapter we explored different ways of partitioning a large dataset into smaller\\nsubsets. Partitioning is necessary when you have so much data that storing and pro‐\\ncessing it on a single machine is no longer feasible.\\n216 | Chapter 6: Partitioning'),\n",
       "   Document(metadata={'page': 237, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='overview of techniques used in parallel databases, please see the references [ 1, 33]. \\nSummary\\nIn this chapter we explored different ways of partitioning a large dataset into smaller\\nsubsets. Partitioning is necessary when you have so much data that storing and pro‐\\ncessing it on a single machine is no longer feasible.\\n216 | Chapter 6: Partitioning'),\n",
       "   Document(metadata={'page': 237, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='overview of techniques used in parallel databases, please see the references [ 1, 33]. \\nSummary\\nIn this chapter we explored different ways of partitioning a large dataset into smaller\\nsubsets. Partitioning is necessary when you have so much data that storing and pro‐\\ncessing it on a single machine is no longer feasible.\\n216 | Chapter 6: Partitioning')]},\n",
       " {'answer': 'According'},\n",
       " {'answer': ' to'},\n",
       " {'answer': ' the'},\n",
       " {'answer': ' provided'},\n",
       " {'answer': ' context'},\n",
       " {'answer': ':'},\n",
       " {'answer': ' Partition'},\n",
       " {'answer': 'ing'},\n",
       " {'answer': ' is'},\n",
       " {'answer': ' necessary'},\n",
       " {'answer': ' when'},\n",
       " {'answer': ' you'},\n",
       " {'answer': ' have'},\n",
       " {'answer': ' so'},\n",
       " {'answer': ' much'},\n",
       " {'answer': ' data'},\n",
       " {'answer': ' that'},\n",
       " {'answer': ' storing'},\n",
       " {'answer': ' and'},\n",
       " {'answer': ' processing'},\n",
       " {'answer': ' it'},\n",
       " {'answer': ' on'},\n",
       " {'answer': ' a'},\n",
       " {'answer': ' single'},\n",
       " {'answer': ' machine'},\n",
       " {'answer': ' is'},\n",
       " {'answer': ' no'},\n",
       " {'answer': ' longer'},\n",
       " {'answer': ' feasible'},\n",
       " {'answer': '.'},\n",
       " {'answer': ''}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided context: Partitioning is necessary when you have so much data that storing and processing it on a single machine is no longer feasible.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([chunk['answer'] for chunk in chunks if 'answer' in chunk.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_response(chain, question, session_id):\n",
    "    async for chunk in chain.astream(\n",
    "        {\"input\": question},\n",
    "        config={\n",
    "            \"configurable\": {\"session_id\": session_id}\n",
    "        }\n",
    "    ):\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
