{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "import os\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LLM: deepseek-coder-v2\n",
      "Using embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "if 'OLLAMA_API_BASE_URL' not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = config('OPENAI_API_KEY')\n",
    "OLLAMA_API_BASE_URL = os.environ['OLLAMA_API_BASE_URL'] if 'OLLAMA_API_BASE_URL' in os.environ else config('OLLAMA_API_BASE_URL')   \n",
    "LLM = os.environ['LLM'] if 'LLM' in os.environ else config('LLM')   \n",
    "EMBEDDING_MODEL = os.environ['EMBEDDING_MODEL'] if 'EMBEDDING_MODEL' in os.environ else config('EMBEDDING_MODEL')  \n",
    "\n",
    "print(f'Using LLM: {LLM}')\n",
    "print(f'Using embedding model: {EMBEDDING_MODEL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_data(file_path, use_splitter=True):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    if use_splitter:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        return loader.load_and_split(text_splitter)\n",
    "    else:\n",
    "        return loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    }
   ],
   "source": [
    "pdf_data = load_pdf_data(\"/Users/stolli/IT/Designing Data-Intensive Applications.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(pdf_data, embedding_model_name, persist_directory=\"chroma_db\"):\n",
    "    embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    return Chroma.from_documents(pdf_data, embedding=embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stolli/miniforge3/envs/llm-app/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/stolli/miniforge3/envs/llm-app/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorstore = create_vectorstore(pdf_data, embedding_model_name=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore.similarity_search_with_score(\"What is partitioning?\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_API_BASE_URL, \n",
    "    model=LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_chain(vectorstore, llm):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    contextualize_q_system_prompt = (\n",
    "        \"Given a chat history and the latest user question \"\n",
    "        \"which might reference context in the chat history, \"\n",
    "        \"formulate a standalone question which can be understood \"\n",
    "        \"without the chat history. Do NOT answer the question, \"\n",
    "        \"just reformulate it if needed and otherwise return it as is.\"\n",
    "    )\n",
    "    contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm, retriever, contextualize_q_prompt\n",
    "    )\n",
    "\n",
    "    system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "        Use the chat history and the following pieces of retrieved context to answer the question. \n",
    "        If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "        If you find the answer, write the answer in a concise way. \n",
    "        Context: {context}\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "\n",
    "    # manage chat history\n",
    "    store = {}\n",
    "    def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "        if session_id not in store:\n",
    "            store[session_id] = ChatMessageHistory()\n",
    "        return store[session_id]\n",
    "\n",
    "    return RunnableWithMessageHistory(\n",
    "        rag_chain,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        output_messages_key=\"answer\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_rag_chain(vectorstore, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is partitioning?',\n",
       " 'chat_history': [],\n",
       " 'context': [Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'),\n",
       "  Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'),\n",
       "  Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'),\n",
       "  Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199')],\n",
       " 'answer': ' Partitioning refers to dividing a large dataset into smaller parts, called partitions, which are stored and managed separately. Each piece of data (such as records, rows, or documents) belongs to exactly one partition. This allows for scalability by distributing the load across multiple nodes in a shared-nothing cluster.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\n",
    "    {\"input\": \"What is partitioning?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you repeat your answer as structured list please?',\n",
       " 'chat_history': [HumanMessage(content='What is partitioning?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=' Partitioning refers to dividing a large dataset into smaller parts, called partitions, which are stored and managed separately. Each piece of data (such as records, rows, or documents) belongs to exactly one partition. This allows for scalability by distributing the load across multiple nodes in a shared-nothing cluster.', additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(metadata={'page': 238, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='The goal of partitioning is to spread the data and query load evenly across multiple\\nmachines, avoiding hot spots (nodes with disproportionately high load). This\\nrequires choosing a partitioning scheme that is appropriate to your data, and reba‐\\nlancing the partitions when nodes are added to or removed from the cluster.\\nWe discussed two main approaches to partitioning:\\n•Key range partitioning , where keys are sorted, and a partition owns all the keys\\nfrom some minimum up to some maximum. Sorting has the advantage that effi‐\\ncient range queries are possible, but there is a risk of hot spots if the application\\noften accesses keys that are close together in the sorted order.\\nIn this approach, partitions are typically rebalanced dynamically by splitting the\\nrange into two subranges when a partition gets too big.\\n•Hash partitioning , where a hash function is applied to each key, and a partition\\nowns a range of hashes. This method destroys the ordering of keys, making range'),\n",
       "  Document(metadata={'page': 238, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='The goal of partitioning is to spread the data and query load evenly across multiple\\nmachines, avoiding hot spots (nodes with disproportionately high load). This\\nrequires choosing a partitioning scheme that is appropriate to your data, and reba‐\\nlancing the partitions when nodes are added to or removed from the cluster.\\nWe discussed two main approaches to partitioning:\\n•Key range partitioning , where keys are sorted, and a partition owns all the keys\\nfrom some minimum up to some maximum. Sorting has the advantage that effi‐\\ncient range queries are possible, but there is a risk of hot spots if the application\\noften accesses keys that are close together in the sorted order.\\nIn this approach, partitions are typically rebalanced dynamically by splitting the\\nrange into two subranges when a partition gets too big.\\n•Hash partitioning , where a hash function is applied to each key, and a partition\\nowns a range of hashes. This method destroys the ordering of keys, making range'),\n",
       "  Document(metadata={'page': 238, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='The goal of partitioning is to spread the data and query load evenly across multiple\\nmachines, avoiding hot spots (nodes with disproportionately high load). This\\nrequires choosing a partitioning scheme that is appropriate to your data, and reba‐\\nlancing the partitions when nodes are added to or removed from the cluster.\\nWe discussed two main approaches to partitioning:\\n•Key range partitioning , where keys are sorted, and a partition owns all the keys\\nfrom some minimum up to some maximum. Sorting has the advantage that effi‐\\ncient range queries are possible, but there is a risk of hot spots if the application\\noften accesses keys that are close together in the sorted order.\\nIn this approach, partitions are typically rebalanced dynamically by splitting the\\nrange into two subranges when a partition gets too big.\\n•Hash partitioning , where a hash function is applied to each key, and a partition\\nowns a range of hashes. This method destroys the ordering of keys, making range'),\n",
       "  Document(metadata={'page': 238, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='The goal of partitioning is to spread the data and query load evenly across multiple\\nmachines, avoiding hot spots (nodes with disproportionately high load). This\\nrequires choosing a partitioning scheme that is appropriate to your data, and reba‐\\nlancing the partitions when nodes are added to or removed from the cluster.\\nWe discussed two main approaches to partitioning:\\n•Key range partitioning , where keys are sorted, and a partition owns all the keys\\nfrom some minimum up to some maximum. Sorting has the advantage that effi‐\\ncient range queries are possible, but there is a risk of hot spots if the application\\noften accesses keys that are close together in the sorted order.\\nIn this approach, partitions are typically rebalanced dynamically by splitting the\\nrange into two subranges when a partition gets too big.\\n•Hash partitioning , where a hash function is applied to each key, and a partition\\nowns a range of hashes. This method destroys the ordering of keys, making range')],\n",
       " 'answer': \" Sure! Here's a structured list explaining what partitioning is:\\n\\n1. **Definition**: Partitioning involves dividing a large dataset into smaller parts, called partitions. Each piece of data belongs to exactly one partition.\\n2. **Purpose**: The main goal of partitioning is to spread the data and query load evenly across multiple machines in a shared-nothing cluster, aiming to avoid hot spots where disproportionately high load occurs on certain nodes.\\n3. **Approaches**: There are two primary methods for partitioning:\\n   - **Key Range Partitioning**: Keys are sorted, and each partition owns all keys from a minimum up to a maximum value. This method allows efficient range queries but carries the risk of hot spots if the application frequently accesses nearby keys in the sorted order. In this approach, partitions may be rebalanced by dynamically splitting ranges when they become too large.\\n   - **Hash Partitioning**: A hash function is applied to each key, and a partition owns a specific range of hashes. This method does not preserve the ordering of keys; instead, it distributes data uniformly across all partitions based on the output of the hash function. Range queries are less efficient in this method because they cannot take advantage of the ordered nature of the keys. However, it helps prevent hot spots by ensuring that each partition handles a roughly equal number of records.\\n\\nBy using these methods, partitioning enhances performance and scalability in large-scale systems where data management is critical.\"}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\n",
    "    {\"input\": \"Can you repeat your answer as structured list please?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistoryAwareRagChain:\n",
    "    def __init__(self, vectorstore, llm):\n",
    "        contextualize_q_system_prompt = (\n",
    "            \"Given a chat history and the latest user question \"\n",
    "            \"which might reference context in the chat history, \"\n",
    "            \"formulate a standalone question which can be understood \"\n",
    "            \"without the chat history. Do NOT answer the question, \"\n",
    "            \"just reformulate it if needed and otherwise return it as is.\"\n",
    "        )\n",
    "        self._contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", contextualize_q_system_prompt),\n",
    "                MessagesPlaceholder(\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self._history_aware_retriever = create_history_aware_retriever(\n",
    "            llm, \n",
    "            vectorstore.as_retriever(), \n",
    "            self._contextualize_q_prompt\n",
    "        )\n",
    "\n",
    "        system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "            Use the chat history and the following pieces of retrieved context to answer the question. \n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "            If you find the answer, write the answer in a concise way. \n",
    "            Context: {context}\"\"\"\n",
    "        self._prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", system_prompt),\n",
    "                MessagesPlaceholder(\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        question_answer_chain = create_stuff_documents_chain(llm, self._prompt)\n",
    "        self._rag_chain = create_retrieval_chain(self._history_aware_retriever, question_answer_chain)\n",
    "        self._rag_chain_with_history = RunnableWithMessageHistory(\n",
    "            self._rag_chain,\n",
    "            self._get_session_history,\n",
    "            input_messages_key=\"input\",\n",
    "            history_messages_key=\"chat_history\",\n",
    "            output_messages_key=\"answer\",\n",
    "        )\n",
    "\n",
    "        self._store = {}\n",
    "    \n",
    "    def _get_session_history(self, session_id: str) -> BaseChatMessageHistory:\n",
    "        if session_id not in self._store:\n",
    "            self._store[session_id] = ChatMessageHistory()\n",
    "        return self._store[session_id]\n",
    "\n",
    "    def invoke(self, query, session_id):\n",
    "        return self._rag_chain_with_history.invoke(\n",
    "            {\"input\": query},\n",
    "            config={\n",
    "                \"configurable\": {\"session_id\": session_id}\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = HistoryAwareRagChain(vectorstore, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is partitioning?',\n",
       " 'chat_history': [],\n",
       " 'context': [Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'),\n",
       "  Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'),\n",
       "  Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'),\n",
       "  Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199')],\n",
       " 'answer': ' Partitioning refers to dividing a large dataset into smaller parts, each part being known as a \"partition.\" Each piece of data (such as a record, row, or document) belongs to exactly one partition. The main purpose of partitioning is scalability, allowing different partitions to be placed on different nodes in a shared-nothing cluster for more efficient processing and handling of large datasets.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('What is partitioning?', session_id='abc123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke('Can you repeat the answer as structured list?', session_id='abc123')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
