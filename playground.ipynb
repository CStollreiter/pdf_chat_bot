{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from PDFChatBot import PDFChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4()).replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'OLLAMA_API_BASE_URL' not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = config('OPENAI_API_KEY')\n",
    "OLLAMA_API_BASE_URL = os.environ['OLLAMA_API_BASE_URL'] if 'OLLAMA_API_BASE_URL' in os.environ else config('OLLAMA_API_BASE_URL')   \n",
    "LLM = os.environ['LLM'] if 'LLM' in os.environ else config('LLM')   \n",
    "EMBEDDING_MODEL = os.environ['EMBEDDING_MODEL'] if 'EMBEDDING_MODEL' in os.environ else config('EMBEDDING_MODEL')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stolli/miniforge3/envs/llm-app/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/stolli/miniforge3/envs/llm-app/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f'Using embedding model: {EMBEDDING_MODEL}')\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LLM: deepseek-coder-v2\n"
     ]
    }
   ],
   "source": [
    "print(f'Using LLM: {LLM}')\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_API_BASE_URL, \n",
    "    model=LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PDF Chatbot ...\n",
      "--- Loading and vectorizing PDF file ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing history aware LLM ---\n"
     ]
    }
   ],
   "source": [
    "chat_bot = PDFChatBot('/Users/stolli/IT/Designing Data-Intensive Applications.pdf', embedding_model, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating response ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the book about? Please summarize it in around 20 sentences. Include a list of the most important topics',\n",
       " 'chat_history': [],\n",
       " 'context': [Document(metadata={'page': 612, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='About the Author\\nMartin Kleppmann  is a researcher in distributed systems at the University of Cam‐\\nbridge, UK. Previously he was a software engineer and entrepreneur at internet com‐\\npanies including LinkedIn and Rapportive, where he worked on large-scale data\\ninfrastructure. In the process he learned a few things the hard way, and he hopes this\\nbook will save you from repeating the same mistakes.\\nMartin is a regular conference speaker, blogger, and open source contributor. He\\nbelieves that profound technical ideas should be accessible to everyone, and that\\ndeeper understanding will help us develop better software.\\nColophon\\nThe animal on the cover of Designing Data-Intensive Applications  is an Indian wild\\nboar ( Sus scrofa cristatus ), a subspecies of wild boar found in India, Myanmar, Nepal,\\nSri Lanka, and Thailand. They are distinctive from European boars in that they have\\nhigher back bristles, no woolly undercoat, and a larger, straighter skull.'),\n",
       "  Document(metadata={'page': 567, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='[26] Gwen Shapira: “ We have a bunch of customers who are implementing ‘database\\ninside-out’ concept and they all ask ‘is anyone else doing it? are we crazy?’ ” twit‐\\nter.com , July 28, 2016.\\n[27] Martin Kleppmann: “ Turning the Database Inside-out with Apache Samza, ” at\\nStrange Loop , September 2014.\\n[28] Peter Van Roy and Seif Haridi: Concepts, Techniques, and Models of Computer\\nProgramming . MIT Press, 2004. ISBN: 978-0-262-22069-9\\n[29] “Juttle Documentation ,” juttle.github.io , 2016.\\n546 | Chapter 12: The Future of Data Systems'),\n",
       "  Document(metadata={'page': 567, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='[26] Gwen Shapira: “ We have a bunch of customers who are implementing ‘database\\ninside-out’ concept and they all ask ‘is anyone else doing it? are we crazy?’ ” twit‐\\nter.com , July 28, 2016.\\n[27] Martin Kleppmann: “ Turning the Database Inside-out with Apache Samza, ” at\\nStrange Loop , September 2014.\\n[28] Peter Van Roy and Seif Haridi: Concepts, Techniques, and Models of Computer\\nProgramming . MIT Press, 2004. ISBN: 978-0-262-22069-9\\n[29] “Juttle Documentation ,” juttle.github.io , 2016.\\n546 | Chapter 12: The Future of Data Systems'),\n",
       "  Document(metadata={'page': 567, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='[26] Gwen Shapira: “ We have a bunch of customers who are implementing ‘database\\ninside-out’ concept and they all ask ‘is anyone else doing it? are we crazy?’ ” twit‐\\nter.com , July 28, 2016.\\n[27] Martin Kleppmann: “ Turning the Database Inside-out with Apache Samza, ” at\\nStrange Loop , September 2014.\\n[28] Peter Van Roy and Seif Haridi: Concepts, Techniques, and Models of Computer\\nProgramming . MIT Press, 2004. ISBN: 978-0-262-22069-9\\n[29] “Juttle Documentation ,” juttle.github.io , 2016.\\n546 | Chapter 12: The Future of Data Systems')],\n",
       " 'answer': ' \"Designing Data-Intensive Applications\" by Martin Kleppmann explores the fundamental principles and technologies behind modern data-intensive applications, such as databases, stream processing systems, and real-time data infrastructure. The book covers various aspects including traditional relational databases, new architectures like NoSQL and NewSQL, the challenges of scalability and consistency in large-scale systems, and the shift towards more distributed and decentralized approaches. Kleppmann discusses how these technologies enable organizations to handle massive volumes of data efficiently and respond rapidly to changes in information. He also addresses the trade-offs between different architectural choices and provides insights into future trends in data systems engineering. Key topics include Apache Kafka for stream processing, Apache Samza as a streaming processor, and the concept of \"database inside-out,\" which involves integrating database functionalities within applications. The book aims to provide readers with a deep understanding of these technologies and their implications for application design and development.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat_bot.get_response('What is the book about? Please summarize it in around 20 sentences. Include a list of the most important topics', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating response ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is partitioning?',\n",
       " 'chat_history': [HumanMessage(content='What is the book about? Please summarize it in around 20 sentences. Include a list of the most important topics', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=' \"Designing Data-Intensive Applications\" by Martin Kleppmann explores the fundamental principles and technologies behind modern data-intensive applications, such as databases, stream processing systems, and real-time data infrastructure. The book covers various aspects including traditional relational databases, new architectures like NoSQL and NewSQL, the challenges of scalability and consistency in large-scale systems, and the shift towards more distributed and decentralized approaches. Kleppmann discusses how these technologies enable organizations to handle massive volumes of data efficiently and respond rapidly to changes in information. He also addresses the trade-offs between different architectural choices and provides insights into future trends in data systems engineering. Key topics include Apache Kafka for stream processing, Apache Samza as a streaming processor, and the concept of \"database inside-out,\" which involves integrating database functionalities within applications. The book aims to provide readers with a deep understanding of these technologies and their implications for application design and development.', additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(metadata={'page': 237, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='overview of techniques used in parallel databases, please see the references [ 1, 33]. \\nSummary\\nIn this chapter we explored different ways of partitioning a large dataset into smaller\\nsubsets. Partitioning is necessary when you have so much data that storing and pro‐\\ncessing it on a single machine is no longer feasible.\\n216 | Chapter 6: Partitioning'),\n",
       "  Document(metadata={'page': 237, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='overview of techniques used in parallel databases, please see the references [ 1, 33]. \\nSummary\\nIn this chapter we explored different ways of partitioning a large dataset into smaller\\nsubsets. Partitioning is necessary when you have so much data that storing and pro‐\\ncessing it on a single machine is no longer feasible.\\n216 | Chapter 6: Partitioning'),\n",
       "  Document(metadata={'page': 237, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='overview of techniques used in parallel databases, please see the references [ 1, 33]. \\nSummary\\nIn this chapter we explored different ways of partitioning a large dataset into smaller\\nsubsets. Partitioning is necessary when you have so much data that storing and pro‐\\ncessing it on a single machine is no longer feasible.\\n216 | Chapter 6: Partitioning'),\n",
       "  Document(metadata={'page': 237, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='overview of techniques used in parallel databases, please see the references [ 1, 33]. \\nSummary\\nIn this chapter we explored different ways of partitioning a large dataset into smaller\\nsubsets. Partitioning is necessary when you have so much data that storing and pro‐\\ncessing it on a single machine is no longer feasible.\\n216 | Chapter 6: Partitioning')],\n",
       " 'answer': ' Partitioning is a technique used in parallel databases to divide a large dataset into smaller subsets, also known as partitions. This method becomes necessary when the amount of data exceeds what can be stored or processed on a single machine. By dividing the data across multiple machines, each machine can handle only a portion of the total data, making it feasible to manage and process larger datasets concurrently.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bot.get_response('What is partitioning?', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating response ---\n"
     ]
    }
   ],
   "source": [
    "chat_bot.get_response('Can you repeat the answer as structured list?', session_id=session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
