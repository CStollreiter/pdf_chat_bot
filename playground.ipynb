{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from PDFChatBot import PDFChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4()).replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'OLLAMA_API_BASE_URL' not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = config('OPENAI_API_KEY')\n",
    "OLLAMA_API_BASE_URL = os.environ['OLLAMA_API_BASE_URL'] if 'OLLAMA_API_BASE_URL' in os.environ else config('OLLAMA_API_BASE_URL')   \n",
    "LLM = os.environ['LLM'] if 'LLM' in os.environ else config('LLM')   \n",
    "EMBEDDING_MODEL = os.environ['EMBEDDING_MODEL'] if 'EMBEDDING_MODEL' in os.environ else config('EMBEDDING_MODEL')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stolli/miniforge3/envs/pdf-chat-bot/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/stolli/miniforge3/envs/pdf-chat-bot/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f'Using embedding model: {EMBEDDING_MODEL}')\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LLM: llama3.1:8b\n"
     ]
    }
   ],
   "source": [
    "print(f'Using LLM: {LLM}')\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_API_BASE_URL, \n",
    "    model=LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PDF Chatbot ...\n",
      "--- Loading and vectorizing PDF file ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing for Object Streams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing history aware retriever ---\n",
      "--- Initializing Q & A chain ---\n",
      "--- Initializing RAG chain ---\n"
     ]
    }
   ],
   "source": [
    "chat_bot = PDFChatBot('/Users/stolli/IT/Designing Data-Intensive Applications.pdf', embedding_model, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Streaming response ---\n",
      "{'input': 'What is partitioning?', 'chat_history': []}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': [Document(metadata={'page': 233, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='both key-range and hash partitioning, and it splits partitions dynamically in either\\ncase.\\nPartitioning proportionally to nodes\\nWith dynamic partitioning, the number of partitions is proportional to the size of the\\ndataset, since the splitting and merging processes keep the size of each partition\\nbetween some fixed minimum and maximum. On the other hand, with a fixed num窶申\n212 | Chapter 6: Partitioning'), Document(metadata={'page': 233, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='both key-range and hash partitioning, and it splits partitions dynamically in either\\ncase.\\nPartitioning proportionally to nodes\\nWith dynamic partitioning, the number of partitions is proportional to the size of the\\ndataset, since the splitting and merging processes keep the size of each partition\\nbetween some fixed minimum and maximum. On the other hand, with a fixed num窶申\n212 | Chapter 6: Partitioning'), Document(metadata={'page': 233, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='both key-range and hash partitioning, and it splits partitions dynamically in either\\ncase.\\nPartitioning proportionally to nodes\\nWith dynamic partitioning, the number of partitions is proportional to the size of the\\ndataset, since the splitting and merging processes keep the size of each partition\\nbetween some fixed minimum and maximum. On the other hand, with a fixed num窶申\n212 | Chapter 6: Partitioning'), Document(metadata={'page': 233, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='both key-range and hash partitioning, and it splits partitions dynamically in either\\ncase.\\nPartitioning proportionally to nodes\\nWith dynamic partitioning, the number of partitions is proportional to the size of the\\ndataset, since the splitting and merging processes keep the size of each partition\\nbetween some fixed minimum and maximum. On the other hand, with a fixed num窶申\n212 | Chapter 6: Partitioning')]}\n",
      "{'answer': 'In'}\n",
      "{'answer': ' the'}\n",
      "{'answer': ' context'}\n",
      "{'answer': ' provided'}\n",
      "{'answer': ','}\n",
      "{'answer': ' partition'}\n",
      "{'answer': 'ing'}\n",
      "{'answer': ' refers'}\n",
      "{'answer': ' to'}\n",
      "{'answer': ' the'}\n",
      "{'answer': ' process'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' dividing'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' into'}\n",
      "{'answer': ' smaller'}\n",
      "{'answer': ','}\n",
      "{'answer': ' more'}\n",
      "{'answer': ' manageable'}\n",
      "{'answer': ' chunks'}\n",
      "{'answer': ' called'}\n",
      "{'answer': ' partitions'}\n",
      "{'answer': ' or'}\n",
      "{'answer': ' buckets'}\n",
      "{'answer': '.'}\n",
      "{'answer': ' This'}\n",
      "{'answer': ' can'}\n",
      "{'answer': ' be'}\n",
      "{'answer': ' done'}\n",
      "{'answer': ' in'}\n",
      "{'answer': ' different'}\n",
      "{'answer': ' ways'}\n",
      "{'answer': ','}\n",
      "{'answer': ' such'}\n",
      "{'answer': ' as'}\n",
      "{'answer': ':\\n\\n'}\n",
      "{'answer': '*'}\n",
      "{'answer': ' Key'}\n",
      "{'answer': '-range'}\n",
      "{'answer': ' partition'}\n",
      "{'answer': 'ing'}\n",
      "{'answer': ':'}\n",
      "{'answer': ' dividing'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' based'}\n",
      "{'answer': ' on'}\n",
      "{'answer': ' a'}\n",
      "{'answer': ' specific'}\n",
      "{'answer': ' range'}\n",
      "{'answer': ' or'}\n",
      "{'answer': ' key'}\n",
      "{'answer': ' value'}\n",
      "{'answer': '\\n'}\n",
      "{'answer': '*'}\n",
      "{'answer': ' Hash'}\n",
      "{'answer': ' partition'}\n",
      "{'answer': 'ing'}\n",
      "{'answer': ':'}\n",
      "{'answer': ' dividing'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' using'}\n",
      "{'answer': ' a'}\n",
      "{'answer': ' hash'}\n",
      "{'answer': ' function'}\n",
      "{'answer': ' to'}\n",
      "{'answer': ' distribute'}\n",
      "{'answer': ' it'}\n",
      "{'answer': ' across'}\n",
      "{'answer': ' multiple'}\n",
      "{'answer': ' partitions'}\n",
      "{'answer': '\\n\\n'}\n",
      "{'answer': 'The'}\n",
      "{'answer': ' goal'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' partition'}\n",
      "{'answer': 'ing'}\n",
      "{'answer': ' is'}\n",
      "{'answer': ' often'}\n",
      "{'answer': ' to'}\n",
      "{'answer': ' improve'}\n",
      "{'answer': ' the'}\n",
      "{'answer': ' performance'}\n",
      "{'answer': ' and'}\n",
      "{'answer': ' scalability'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' databases'}\n",
      "{'answer': ' or'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' storage'}\n",
      "{'answer': ' systems'}\n",
      "{'answer': ' by'}\n",
      "{'answer': ' reducing'}\n",
      "{'answer': ' the'}\n",
      "{'answer': ' load'}\n",
      "{'answer': ' on'}\n",
      "{'answer': ' individual'}\n",
      "{'answer': ' partitions'}\n",
      "{'answer': ' and'}\n",
      "{'answer': ' allowing'}\n",
      "{'answer': ' for'}\n",
      "{'answer': ' more'}\n",
      "{'answer': ' efficient'}\n",
      "{'answer': ' querying'}\n",
      "{'answer': ' and'}\n",
      "{'answer': ' access'}\n",
      "{'answer': ' to'}\n",
      "{'answer': ' data'}\n",
      "{'answer': '.'}\n",
      "{'answer': ''}\n"
     ]
    }
   ],
   "source": [
    "stream_response = []\n",
    "for chunk in chat_bot.stream_response('What is partitioning?', session_id):\n",
    "    stream_response.append(chunk)\n",
    "    print(chunk, end=\"\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the context provided, partitioning refers to the process of dividing data into smaller, more manageable chunks called partitions or buckets. This can be done in different ways, such as:\\n\\n* Key-range partitioning: dividing data based on a specific range or key value\\n* Hash partitioning: dividing data using a hash function to distribute it across multiple partitions\\n\\nThe goal of partitioning is often to improve the performance and scalability of databases or data storage systems by reducing the load on individual partitions and allowing for more efficient querying and access to data.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([chunk['answer'] for chunk in stream_response if 'answer' in chunk.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating response ---\n"
     ]
    }
   ],
   "source": [
    "response = chat_bot.get_response('What is the book about? Please summarize it in around 20 sentences. Include a list of the most important topics', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I couldn't find any information about the main topic or theme of the book. However, I can try to provide some general insights based on the snippets you've shared.\n",
      "\n",
      "The book appears to be discussing various concepts related to computer science and programming, specifically in the area of concurrency and synchronization. The text mentions linearizability, consistent snapshots, and lock contention, which suggests that the book may cover topics such as:\n",
      "\n",
      "**Most Important Topics:**\n",
      "\n",
      "1. Linearizability\n",
      "2. Consistent Snapshots\n",
      "3. Lock Contention\n",
      "4. Concurrency and Synchronization\n",
      "5. Data Partitioning\n",
      "\n",
      "Unfortunately, without more context or information about the book's content, I couldn't provide a detailed summary or insights into its main theme.\n",
      "\n",
      "However, based on the snippets provided, here's a possible outline of what the book might cover:\n",
      "\n",
      "* Chapter 1: Introduction to Concurrency and Synchronization\n",
      "\t+ Overview of concurrency challenges and synchronization techniques\n",
      "* Chapter 2: Linearizability\n",
      "\t+ Definition and importance of linearizability in concurrent systems\n",
      "\t+ Examples of non-linearizable operations\n",
      "* Chapter 3: Consistent Snapshots\n",
      "\t+ Concept of consistent snapshots and their application in concurrent systems\n",
      "\t+ Avoiding lock contention through consistent snapshots\n",
      "* Chapter 4: Data Partitioning\n",
      "\t+ Types of partitioning techniques (key-range, hash, etc.)\n",
      "\t+ Benefits and challenges of data partitioning\n",
      "\n",
      "Please note that this is a highly speculative outline, and the actual content of the book may differ significantly.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on page 261) is not linearizable: by design, it makes reads from a consistent snapshot,\\nto avoid lock contention between readers and writers. The whole point of a consistent\\nsnapshot is that it does not include writes that are more recent than the snapshot, and\\nthus reads from the snapshot are not linearizable.\\nLinearizability | 329'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context'][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 350\n",
      "Content: on page 261) is not linearizable: by design, it makes reads from a consistent snapshot,\n",
      "to avoid lock contention between readers and writers. The whole point of a consistent\n",
      "snapshot is that it does not include writes that are more recent than the snapshot, and\n",
      "thus reads from the snapshot are not linearizable.\n",
      "Linearizability | 329\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 350\n",
      "Content: on page 261) is not linearizable: by design, it makes reads from a consistent snapshot,\n",
      "to avoid lock contention between readers and writers. The whole point of a consistent\n",
      "snapshot is that it does not include writes that are more recent than the snapshot, and\n",
      "thus reads from the snapshot are not linearizable.\n",
      "Linearizability | 329\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 350\n",
      "Content: on page 261) is not linearizable: by design, it makes reads from a consistent snapshot,\n",
      "to avoid lock contention between readers and writers. The whole point of a consistent\n",
      "snapshot is that it does not include writes that are more recent than the snapshot, and\n",
      "thus reads from the snapshot are not linearizable.\n",
      "Linearizability | 329\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 350\n",
      "Content: on page 261) is not linearizable: by design, it makes reads from a consistent snapshot,\n",
      "to avoid lock contention between readers and writers. The whole point of a consistent\n",
      "snapshot is that it does not include writes that are more recent than the snapshot, and\n",
      "thus reads from the snapshot are not linearizable.\n",
      "Linearizability | 329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in response['context']:\n",
    "    print(f'Source: {document.metadata[\"source\"]}')\n",
    "    print(f'Page: {document.metadata[\"page\"]}')\n",
    "    print(f'Content: {document.page_content}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_bot.get_response('What is partitioning?', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_bot.get_response('Can you repeat the answer as structured list?', session_id=session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
