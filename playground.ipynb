{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from PDFChatBot import PDFChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4()).replace('-', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'OLLAMA_API_BASE_URL' not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = config('OPENAI_API_KEY')\n",
    "OLLAMA_API_BASE_URL = os.environ['OLLAMA_API_BASE_URL'] if 'OLLAMA_API_BASE_URL' in os.environ else config('OLLAMA_API_BASE_URL')   \n",
    "LLM = os.environ['LLM'] if 'LLM' in os.environ else config('LLM')   \n",
    "EMBEDDING_MODEL = os.environ['EMBEDDING_MODEL'] if 'EMBEDDING_MODEL' in os.environ else config('EMBEDDING_MODEL')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stolli/miniforge3/envs/pdf-chat-bot/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/stolli/miniforge3/envs/pdf-chat-bot/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f'Using embedding model: {EMBEDDING_MODEL}')\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LLM: llama3.1:8b\n"
     ]
    }
   ],
   "source": [
    "print(f'Using LLM: {LLM}')\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_API_BASE_URL, \n",
    "    model=LLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_bot = PDFChatBot(embedding_model, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    }
   ],
   "source": [
    "chat_bot.add_pdf_data(pdf_file_path='/Users/stolli/IT/Designing Data-Intensive Applications.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What is partitioning?', 'chat_history': []}\n",
      "{'context': [Document(metadata={'page': 220, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Terminological confusion\\nWhat we call a partition  here is called a shard  in MongoDB, Elas‐\\nticsearch, and SolrCloud; it’s known as a region  in HBase, a tablet\\nin Bigtable, a vnode  in Cassandra and Riak, and a vBucket  in\\nCouchbase. However, partitioning  is the most established term, so\\nwe’ll stick with that.\\nNormally, partitions are defined in such a way that each piece of data (each record,\\nrow, or document) belongs to exactly one partition. There are various ways of achiev‐\\ning this, which we discuss in depth in this chapter. In effect, each partition is a small\\ndatabase of its own, although the database may support operations that touch multi‐\\nple partitions at the same time.\\nThe main reason for wanting to partition data is scalability . Different partitions can\\nbe placed on different nodes in a shared-nothing cluster (see the introduction to\\n199'), Document(metadata={'page': 238, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='The goal of partitioning is to spread the data and query load evenly across multiple\\nmachines, avoiding hot spots (nodes with disproportionately high load). This\\nrequires choosing a partitioning scheme that is appropriate to your data, and reba‐\\nlancing the partitions when nodes are added to or removed from the cluster.\\nWe discussed two main approaches to partitioning:\\n•Key range partitioning , where keys are sorted, and a partition owns all the keys\\nfrom some minimum up to some maximum. Sorting has the advantage that effi‐\\ncient range queries are possible, but there is a risk of hot spots if the application\\noften accesses keys that are close together in the sorted order.\\nIn this approach, partitions are typically rebalanced dynamically by splitting the\\nrange into two subranges when a partition gets too big.\\n•Hash partitioning , where a hash function is applied to each key, and a partition\\nowns a range of hashes. This method destroys the ordering of keys, making range'), Document(metadata={'page': 233, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='both key-range and hash partitioning, and it splits partitions dynamically in either\\ncase.\\nPartitioning proportionally to nodes\\nWith dynamic partitioning, the number of partitions is proportional to the size of the\\ndataset, since the splitting and merging processes keep the size of each partition\\nbetween some fixed minimum and maximum. On the other hand, with a fixed num‐\\n212 | Chapter 6: Partitioning'), Document(metadata={'page': 221, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='90): this difference affects how the system is tuned, but the fundamentals of partition‐\\ning apply to both kinds of workloads.\\nIn this chapter we will first look at different approaches for partitioning large datasets\\nand observe how the indexing of data interacts with partitioning. We’ll then talk\\nabout rebalancing, which is necessary if you want to add or remove nodes in your\\ncluster. Finally, we’ll get an overview of how databases route requests to the right par‐\\ntitions and execute queries.\\nPartitioning and Replication\\nPartitioning is usually combined with replication so that copies of each partition are\\nstored on multiple nodes. This means that, even though each record belongs to\\nexactly one partition, it may still be stored on several different nodes for fault toler‐\\nance.\\nA node may store more than one partition. If a leader–follower replication model is\\nused, the combination of partitioning and replication can look like Figure 6-1 . Each')]}\n",
      "{'answer': 'Partition'}\n",
      "{'answer': 'ing'}\n",
      "{'answer': ' is'}\n",
      "{'answer': ' splitting'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' into'}\n",
      "{'answer': ' smaller'}\n",
      "{'answer': ' pieces'}\n",
      "{'answer': ' called'}\n",
      "{'answer': ' partitions'}\n",
      "{'answer': ' or'}\n",
      "{'answer': ' shards'}\n",
      "{'answer': ','}\n",
      "{'answer': ' each'}\n",
      "{'answer': ' containing'}\n",
      "{'answer': ' a'}\n",
      "{'answer': ' portion'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' the'}\n",
      "{'answer': ' total'}\n",
      "{'answer': ' dataset'}\n",
      "{'answer': '.'}\n",
      "{'answer': ' Each'}\n",
      "{'answer': ' piece'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' ('}\n",
      "{'answer': 'record'}\n",
      "{'answer': ','}\n",
      "{'answer': ' row'}\n",
      "{'answer': ','}\n",
      "{'answer': ' or'}\n",
      "{'answer': ' document'}\n",
      "{'answer': ')'}\n",
      "{'answer': ' belongs'}\n",
      "{'answer': ' to'}\n",
      "{'answer': ' exactly'}\n",
      "{'answer': ' one'}\n",
      "{'answer': ' partition'}\n",
      "{'answer': '.'}\n",
      "{'answer': ' Part'}\n",
      "{'answer': 'itions'}\n",
      "{'answer': ' can'}\n",
      "{'answer': ' be'}\n",
      "{'answer': ' thought'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' as'}\n",
      "{'answer': ' small'}\n",
      "{'answer': ' databases'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' their'}\n",
      "{'answer': ' own'}\n",
      "{'answer': ','}\n",
      "{'answer': ' although'}\n",
      "{'answer': ' the'}\n",
      "{'answer': ' main'}\n",
      "{'answer': ' database'}\n",
      "{'answer': ' may'}\n",
      "{'answer': ' support'}\n",
      "{'answer': ' operations'}\n",
      "{'answer': ' that'}\n",
      "{'answer': ' touch'}\n",
      "{'answer': ' multiple'}\n",
      "{'answer': ' partitions'}\n",
      "{'answer': ' at'}\n",
      "{'answer': ' the'}\n",
      "{'answer': ' same'}\n",
      "{'answer': ' time'}\n",
      "{'answer': '.'}\n",
      "{'answer': ' The'}\n",
      "{'answer': ' goal'}\n",
      "{'answer': ' of'}\n",
      "{'answer': ' partition'}\n",
      "{'answer': 'ing'}\n",
      "{'answer': ' is'}\n",
      "{'answer': ' to'}\n",
      "{'answer': ' spread'}\n",
      "{'answer': ' the'}\n",
      "{'answer': ' data'}\n",
      "{'answer': ' and'}\n",
      "{'answer': ' query'}\n",
      "{'answer': ' load'}\n",
      "{'answer': ' evenly'}\n",
      "{'answer': ' across'}\n",
      "{'answer': ' multiple'}\n",
      "{'answer': ' machines'}\n",
      "{'answer': ','}\n",
      "{'answer': ' improving'}\n",
      "{'answer': ' scalability'}\n",
      "{'answer': ' and'}\n",
      "{'answer': ' avoiding'}\n",
      "{'answer': ' hot'}\n",
      "{'answer': ' spots'}\n",
      "{'answer': ' ('}\n",
      "{'answer': 'nodes'}\n",
      "{'answer': ' with'}\n",
      "{'answer': ' disproportionately'}\n",
      "{'answer': ' high'}\n",
      "{'answer': ' load'}\n",
      "{'answer': ').'}\n",
      "{'answer': ''}\n"
     ]
    }
   ],
   "source": [
    "stream_response = []\n",
    "for chunk in chat_bot.stream_response('What is partitioning?', session_id):\n",
    "    stream_response.append(chunk)\n",
    "    print(chunk, end=\"\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Partitioning is splitting data into smaller pieces called partitions or shards, each containing a portion of the total dataset. Each piece of data (record, row, or document) belongs to exactly one partition. Partitions can be thought of as small databases of their own, although the main database may support operations that touch multiple partitions at the same time. The goal of partitioning is to spread the data and query load evenly across multiple machines, improving scalability and avoiding hot spots (nodes with disproportionately high load).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([chunk['answer'] for chunk in stream_response if 'answer' in chunk.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_bot.get_response('What is the book about? Please summarize it in around 20 sentences. Include a list of the most important topics', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book \"Designing Data-Intensive Applications\" is about designing and building large-scale data systems that can handle massive amounts of data and scale to meet the needs of modern applications.\n",
      "\n",
      "The authors, Martin Kleppmann and others, draw on their experience in building distributed data systems to provide a comprehensive guide to designing data-intensive applications.\n",
      "\n",
      "The book focuses on the architecture of data systems and how they are integrated into data-intensive applications. It doesn't cover deployment, operations, security, management, and other areas that are complex and important topics.\n",
      "\n",
      "The authors explain that most books about data systems focus on the technical details, but this one takes a more general approach to designing data-intensive applications.\n",
      "\n",
      "They explore the challenges of building large-scale data systems and how to overcome them. The book covers various aspects of designing data-intensive applications, including:\n",
      "\n",
      "**Most Important Topics:**\n",
      "\n",
      "1. **Data Partitioning**: splitting data into smaller pieces called partitions or shards.\n",
      "2. **Distributed Data Systems**: designing systems that can handle massive amounts of data across multiple machines.\n",
      "3. **Scalability**: building systems that can scale to meet the needs of modern applications.\n",
      "4. **Availability**: ensuring that data is always available and accessible.\n",
      "5. **Consistency**: ensuring that data is accurate and up-to-date.\n",
      "6. **Data Ingestion**: handling massive amounts of data coming in from various sources.\n",
      "7. **Querying Data**: designing systems to efficiently query large datasets.\n",
      "\n",
      "The authors also discuss the importance of understanding the trade-offs between consistency, availability, and partition tolerance (CAP theorem) when designing distributed data systems.\n",
      "\n",
      "Throughout the book, the authors share real-world examples and case studies to illustrate key concepts and provide practical advice for building scalable and reliable data-intensive applications.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 20, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='McCaffrey, Josie McLellan, Christopher Meiklejohn, Ian Meyers, Neha Narkhede,\\nNeha Narula, Cathy O’Neil, Onora O’Neill, Ludovic Orban, Zoran Perkov, Julia\\nPowles, Chris Riccomini, Henry Robinson, David Rosenthal, Jennifer Rullmann,\\nMatthew Sackman, Martin Scholl, Amit Sela, Gwen Shapira, Greg Spurrier, Sam\\nStokes, Ben Stopford, Tom Stuart, Diana Vasile, Rahul Vohra, Pete Warden, and\\nBrett Wooldridge.\\nSeveral more people have been invaluable to the writing of this book by reviewing\\ndrafts and providing feedback. For these contributions I am particularly indebted to\\nRaul Agepati, Tyler Akidau, Mattias Andersson, Sasha Baranov, Veena Basavaraj,\\nDavid Beyer, Jim Brikman, Paul Carey, Raul Castro Fernandez, Joseph Chow, Derek\\nElkins, Sam Elliott, Alexander Gallego, Mark Grover, Stu Halloway, Heidi Howard,\\nNicola Kleppmann, Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski,\\nPhil Potter, Hamid Ramazani, Sam Stokes, and Ben Summers. Of course, I take all'),\n",
       " Document(metadata={'page': 17, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='In the ebook editions we have included links to the full text of online resources. All\\nlinks were verified at the time of publication, but unfortunately links tend to break\\nfrequently due to the nature of the web. If you come across a broken link, or if you\\nare reading a print copy of this book, you can look up references using a search\\nengine. For academic papers, you can search for the title in Google Scholar to find\\nopen-access PDF files. Alternatively, you can find all of the references at https://\\ngithub.com/ept/ddia-references , where we maintain up-to-date links.\\nWe look primarily at the architecture  of data systems and the ways they are integrated\\ninto data-intensive applications. This book doesn’t have space to cover deployment,\\noperations, security, management, and other areas—those are complex and impor‐\\ntant topics, and we wouldn’t do them justice by making them superficial side notes in\\nthis book. They deserve books of their own.'),\n",
       " Document(metadata={'page': 19, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='How to Contact Us\\nPlease address comments and questions concerning this book to the publisher:\\nO’Reilly Media, Inc.\\n1005 Gravenstein Highway North\\nSebastopol, CA 95472\\n800-998-9938 (in the United States or Canada)\\n707-829-0515 (international or local)\\n707-829-0104 (fax)\\nWe have a web page for this book, where we list errata, examples, and any additional\\ninformation. You can access this page at http://bit.ly/designing-data-intensive-apps .\\nTo comment or ask technical questions about this book, send email to bookques‐\\ntions@oreilly.com .\\nFor more information about our books, courses, conferences, and news, see our web‐\\nsite at http://www.oreilly.com .\\nFind us on Facebook: http://facebook.com/oreilly\\nFollow us on Twitter: http://twitter.com/oreillymedia\\nWatch us on YouTube: http://www.youtube.com/oreillymedia\\nAcknowledgments\\nThis book is an amalgamation and systematization of a large number of other peo‐\\nple’s ideas and knowledge, combining experience from both academic research and'),\n",
       " Document(metadata={'page': 20, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Nicola Kleppmann, Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski,\\nPhil Potter, Hamid Ramazani, Sam Stokes, and Ben Summers. Of course, I take all\\nresponsibility for any remaining errors or unpalatable opinions in this book.\\nFor helping this book become real, and for their patience with my slow writing and\\nunusual requests, I am grateful to my editors Marie Beaugureau, Mike Loukides, Ann\\nSpencer, and all the team at O’Reilly. For helping find the right words, I thank Rachel\\nHead. For giving me the time and freedom to write in spite of other work commit‐\\nments, I thank Alastair Beresford, Susan Goodhue, Neha Narkhede, and Kevin Scott.\\nVery special thanks are due to Shabbir Diwan and Edie Freedman, who illustrated\\nwith great care the maps that accompany the chapters. It’s wonderful that they took\\non the unconventional idea of creating maps, and made them so beautiful and com‐\\npelling.\\nFinally, my love goes to my family and friends, without whom I would not have been')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 20, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='McCaffrey, Josie McLellan, Christopher Meiklejohn, Ian Meyers, Neha Narkhede,\\nNeha Narula, Cathy O’Neil, Onora O’Neill, Ludovic Orban, Zoran Perkov, Julia\\nPowles, Chris Riccomini, Henry Robinson, David Rosenthal, Jennifer Rullmann,\\nMatthew Sackman, Martin Scholl, Amit Sela, Gwen Shapira, Greg Spurrier, Sam\\nStokes, Ben Stopford, Tom Stuart, Diana Vasile, Rahul Vohra, Pete Warden, and\\nBrett Wooldridge.\\nSeveral more people have been invaluable to the writing of this book by reviewing\\ndrafts and providing feedback. For these contributions I am particularly indebted to\\nRaul Agepati, Tyler Akidau, Mattias Andersson, Sasha Baranov, Veena Basavaraj,\\nDavid Beyer, Jim Brikman, Paul Carey, Raul Castro Fernandez, Joseph Chow, Derek\\nElkins, Sam Elliott, Alexander Gallego, Mark Grover, Stu Halloway, Heidi Howard,\\nNicola Kleppmann, Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski,\\nPhil Potter, Hamid Ramazani, Sam Stokes, and Ben Summers. Of course, I take all'),\n",
       " Document(metadata={'page': 17, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='In the ebook editions we have included links to the full text of online resources. All\\nlinks were verified at the time of publication, but unfortunately links tend to break\\nfrequently due to the nature of the web. If you come across a broken link, or if you\\nare reading a print copy of this book, you can look up references using a search\\nengine. For academic papers, you can search for the title in Google Scholar to find\\nopen-access PDF files. Alternatively, you can find all of the references at https://\\ngithub.com/ept/ddia-references , where we maintain up-to-date links.\\nWe look primarily at the architecture  of data systems and the ways they are integrated\\ninto data-intensive applications. This book doesn’t have space to cover deployment,\\noperations, security, management, and other areas—those are complex and impor‐\\ntant topics, and we wouldn’t do them justice by making them superficial side notes in\\nthis book. They deserve books of their own.'),\n",
       " Document(metadata={'page': 19, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='How to Contact Us\\nPlease address comments and questions concerning this book to the publisher:\\nO’Reilly Media, Inc.\\n1005 Gravenstein Highway North\\nSebastopol, CA 95472\\n800-998-9938 (in the United States or Canada)\\n707-829-0515 (international or local)\\n707-829-0104 (fax)\\nWe have a web page for this book, where we list errata, examples, and any additional\\ninformation. You can access this page at http://bit.ly/designing-data-intensive-apps .\\nTo comment or ask technical questions about this book, send email to bookques‐\\ntions@oreilly.com .\\nFor more information about our books, courses, conferences, and news, see our web‐\\nsite at http://www.oreilly.com .\\nFind us on Facebook: http://facebook.com/oreilly\\nFollow us on Twitter: http://twitter.com/oreillymedia\\nWatch us on YouTube: http://www.youtube.com/oreillymedia\\nAcknowledgments\\nThis book is an amalgamation and systematization of a large number of other peo‐\\nple’s ideas and knowledge, combining experience from both academic research and'),\n",
       " Document(metadata={'page': 20, 'source': '/Users/stolli/IT/Designing Data-Intensive Applications.pdf'}, page_content='Nicola Kleppmann, Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski,\\nPhil Potter, Hamid Ramazani, Sam Stokes, and Ben Summers. Of course, I take all\\nresponsibility for any remaining errors or unpalatable opinions in this book.\\nFor helping this book become real, and for their patience with my slow writing and\\nunusual requests, I am grateful to my editors Marie Beaugureau, Mike Loukides, Ann\\nSpencer, and all the team at O’Reilly. For helping find the right words, I thank Rachel\\nHead. For giving me the time and freedom to write in spite of other work commit‐\\nments, I thank Alastair Beresford, Susan Goodhue, Neha Narkhede, and Kevin Scott.\\nVery special thanks are due to Shabbir Diwan and Edie Freedman, who illustrated\\nwith great care the maps that accompany the chapters. It’s wonderful that they took\\non the unconventional idea of creating maps, and made them so beautiful and com‐\\npelling.\\nFinally, my love goes to my family and friends, without whom I would not have been')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "[res.append(x) for x in response['context'] if x not in res]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'McCaffrey, Josie McLellan, Christopher Meiklejohn, Ian Meyers, Neha Narkhede,\\nNeha Narula, Cathy O’Neil, Onora O’Neill, Ludovic Orban, Zoran Perkov, Julia\\nPowles, Chris Riccomini, Henry Robinson, David Rosenthal, Jennifer Rullmann,\\nMatthew Sackman, Martin Scholl, Amit Sela, Gwen Shapira, Greg Spurrier, Sam\\nStokes, Ben Stopford, Tom Stuart, Diana Vasile, Rahul Vohra, Pete Warden, and\\nBrett Wooldridge.\\nSeveral more people have been invaluable to the writing of this book by reviewing\\ndrafts and providing feedback. For these contributions I am particularly indebted to\\nRaul Agepati, Tyler Akidau, Mattias Andersson, Sasha Baranov, Veena Basavaraj,\\nDavid Beyer, Jim Brikman, Paul Carey, Raul Castro Fernandez, Joseph Chow, Derek\\nElkins, Sam Elliott, Alexander Gallego, Mark Grover, Stu Halloway, Heidi Howard,\\nNicola Kleppmann, Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski,\\nPhil Potter, Hamid Ramazani, Sam Stokes, and Ben Summers. Of course, I take all'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context'][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 20\n",
      "Content: McCaffrey, Josie McLellan, Christopher Meiklejohn, Ian Meyers, Neha Narkhede,\n",
      "Neha Narula, Cathy O’Neil, Onora O’Neill, Ludovic Orban, Zoran Perkov, Julia\n",
      "Powles, Chris Riccomini, Henry Robinson, David Rosenthal, Jennifer Rullmann,\n",
      "Matthew Sackman, Martin Scholl, Amit Sela, Gwen Shapira, Greg Spurrier, Sam\n",
      "Stokes, Ben Stopford, Tom Stuart, Diana Vasile, Rahul Vohra, Pete Warden, and\n",
      "Brett Wooldridge.\n",
      "Several more people have been invaluable to the writing of this book by reviewing\n",
      "drafts and providing feedback. For these contributions I am particularly indebted to\n",
      "Raul Agepati, Tyler Akidau, Mattias Andersson, Sasha Baranov, Veena Basavaraj,\n",
      "David Beyer, Jim Brikman, Paul Carey, Raul Castro Fernandez, Joseph Chow, Derek\n",
      "Elkins, Sam Elliott, Alexander Gallego, Mark Grover, Stu Halloway, Heidi Howard,\n",
      "Nicola Kleppmann, Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski,\n",
      "Phil Potter, Hamid Ramazani, Sam Stokes, and Ben Summers. Of course, I take all\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 17\n",
      "Content: In the ebook editions we have included links to the full text of online resources. All\n",
      "links were verified at the time of publication, but unfortunately links tend to break\n",
      "frequently due to the nature of the web. If you come across a broken link, or if you\n",
      "are reading a print copy of this book, you can look up references using a search\n",
      "engine. For academic papers, you can search for the title in Google Scholar to find\n",
      "open-access PDF files. Alternatively, you can find all of the references at https://\n",
      "github.com/ept/ddia-references , where we maintain up-to-date links.\n",
      "We look primarily at the architecture  of data systems and the ways they are integrated\n",
      "into data-intensive applications. This book doesn’t have space to cover deployment,\n",
      "operations, security, management, and other areas—those are complex and impor‐\n",
      "tant topics, and we wouldn’t do them justice by making them superficial side notes in\n",
      "this book. They deserve books of their own.\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 19\n",
      "Content: How to Contact Us\n",
      "Please address comments and questions concerning this book to the publisher:\n",
      "O’Reilly Media, Inc.\n",
      "1005 Gravenstein Highway North\n",
      "Sebastopol, CA 95472\n",
      "800-998-9938 (in the United States or Canada)\n",
      "707-829-0515 (international or local)\n",
      "707-829-0104 (fax)\n",
      "We have a web page for this book, where we list errata, examples, and any additional\n",
      "information. You can access this page at http://bit.ly/designing-data-intensive-apps .\n",
      "To comment or ask technical questions about this book, send email to bookques‐\n",
      "tions@oreilly.com .\n",
      "For more information about our books, courses, conferences, and news, see our web‐\n",
      "site at http://www.oreilly.com .\n",
      "Find us on Facebook: http://facebook.com/oreilly\n",
      "Follow us on Twitter: http://twitter.com/oreillymedia\n",
      "Watch us on YouTube: http://www.youtube.com/oreillymedia\n",
      "Acknowledgments\n",
      "This book is an amalgamation and systematization of a large number of other peo‐\n",
      "ple’s ideas and knowledge, combining experience from both academic research and\n",
      "\n",
      "Source: /Users/stolli/IT/Designing Data-Intensive Applications.pdf\n",
      "Page: 20\n",
      "Content: Nicola Kleppmann, Stefan Kruppa, Bjorn Madsen, Sander Mak, Stefan Podkowinski,\n",
      "Phil Potter, Hamid Ramazani, Sam Stokes, and Ben Summers. Of course, I take all\n",
      "responsibility for any remaining errors or unpalatable opinions in this book.\n",
      "For helping this book become real, and for their patience with my slow writing and\n",
      "unusual requests, I am grateful to my editors Marie Beaugureau, Mike Loukides, Ann\n",
      "Spencer, and all the team at O’Reilly. For helping find the right words, I thank Rachel\n",
      "Head. For giving me the time and freedom to write in spite of other work commit‐\n",
      "ments, I thank Alastair Beresford, Susan Goodhue, Neha Narkhede, and Kevin Scott.\n",
      "Very special thanks are due to Shabbir Diwan and Edie Freedman, who illustrated\n",
      "with great care the maps that accompany the chapters. It’s wonderful that they took\n",
      "on the unconventional idea of creating maps, and made them so beautiful and com‐\n",
      "pelling.\n",
      "Finally, my love goes to my family and friends, without whom I would not have been\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document in response['context']:\n",
    "    print(f'Source: {document.metadata[\"source\"]}')\n",
    "    print(f'Page: {document.metadata[\"page\"]}')\n",
    "    print(f'Content: {document.page_content}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_bot.get_response('What is partitioning?', session_id=session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_bot.get_response('Can you repeat the answer as structured list?', session_id=session_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
